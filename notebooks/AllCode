
01_data_collection.ipynb

import pandas as pd
import logging
import os
from pathlib import Path


# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def is_safe_path(base_path, path, follow_symlinks=True):
    """Check if the path is safe to open.

    Args:
        base_path (str): The base directory against which to check the path.
        path (str): The path to check.
        follow_symlinks (bool): Whether to follow symlinks.

    Returns:
        bool: True if the path is safe, False otherwise.
    """
    # Resolve to absolute paths
    base_path = Path(base_path).resolve()
    target_path = Path(path).resolve()

    # Check if the target path is within the base path
    return base_path in target_path.parents or target_path == base_path

def validate_csv_file_path(file_path):
    """Validates the given file path to ensure it points to a CSV file and is safe.
    
    Args:
        file_path (str): The file path to validate.
        
    Returns:
        bool: True if the file path is valid and safe, False otherwise.
    """
    if not file_path.endswith('.csv'):
        logging.error("Invalid file format. File must be a CSV.")
        return False

    base_path = "../data/raw/diabetes.csv"
    if not is_safe_path(base_path, file_path):
        logging.error(f"Access to the path is not allowed: {file_path}")
        return False

    if not os.path.exists(file_path):
        logging.error(f"File not found: {file_path}")
        return False

    return True

def load_diabetes_data(file_path):
    """Loads the Pima Indians Diabetes dataset from the given file path.
    
    Args:
        file_path (str): The path to the CSV file containing the dataset.
        
    Returns:
        pandas.DataFrame: The loaded dataset, or None if an issue occurs.
    """
    if not validate_csv_file_path(file_path):
        return None
    
    try:
        df = pd.read_csv(file_path)
        logging.info("Dataset loaded successfully.")
        return df
    except pd.errors.ParserError as pe:
        logging.error(f"Error parsing CSV file: {pe}")
        return None
    except Exception as e:
        logging.error(f"An error occurred while loading the dataset: {str(e)}")
        return None

def display_dataset_information(dataframe):
    """Displays information about the dataset.
    
    Args:
        dataframe (pandas.DataFrame): The dataset to display information for.
    """
    if dataframe is not None:
        print(dataframe.info())
        print(dataframe.describe())
        print(dataframe.isnull().sum())
        print(dataframe.head())
    else:
        logging.warning("No dataset to display information for.")

if __name__ == "__main__":
    data_path = "../data/raw/diabetes.csv"
    diabetes_data = load_diabetes_data(data_path)
    display_dataset_information(diabetes_data)



02_data_cleaning_and_preprocessing

import pandas as pd
import numpy as np
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler
import json
import logging
from pathlib import Path

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def load_config(config_path='../config/config.json'):
    """Loads configuration from a JSON file."""
    try:
        with open(config_path, 'r') as file:
            return json.load(file)
    except FileNotFoundError:
        logging.error(f"Configuration file not found: {config_path}")
        return None

def load_data(file_path):
    """Loads data from the specified file path."""
    try:
        return pd.read_csv(file_path)
    except FileNotFoundError:
        logging.error(f"File not found: {file_path}")
        return None
    except pd.errors.EmptyDataError:
        logging.error("File is empty.")
        return None
    except Exception as e:
        logging.error(f"An error occurred while loading the dataset: {e}")
        return None

def preprocess_data(data):
    """Preprocesses the dataset."""
    # Identify and handle missing values
    columns_with_zeros = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']
    data[columns_with_zeros] = data[columns_with_zeros].replace(0, np.nan)
    
    # Impute missing values using the median
    imputer = SimpleImputer(strategy='median')
    data[columns_with_zeros] = imputer.fit_transform(data[columns_with_zeros])
    
    # Feature scaling
    scaler = StandardScaler()
    columns_to_scale = data.columns.drop('Outcome')
    data_scaled = pd.DataFrame(scaler.fit_transform(data[columns_to_scale]), columns=columns_to_scale)
    data_scaled['Outcome'] = data['Outcome']
    
    return data_scaled

def save_data(data, file_path):
    """Saves the preprocessed data to the specified file path."""
    try:
        data.to_csv(file_path, index=False)
        logging.info(f"Data saved successfully to {file_path}")
    except Exception as e:
        logging.error(f"Failed to save data: {e}")

def main():
    config = load_config()
    if config is None:
        return
    
    data_path = Path(config['data_path'])
    processed_data_path = Path(config['processed_data_path'])
    
    diabetes_data = load_data(data_path)
    if diabetes_data is not None:
        preprocessed_data = preprocess_data(diabetes_data)
        save_data(preprocessed_data, processed_data_path)

if __name__ == "__main__":
    main()


03_exploratory_data_analysis

# Import necessary modules
import sys
import pandas as pd
import plotly.express as px
import plotly.figure_factory as ff

# Adjust the path to include the Helpers directory
sys.path.append('../Helpers')

# Import custom functions from data_helpers.py
from data_helpers import load_config, load_data

# Load configuration settings from a JSON file
config = load_config('../config/config.json')  # Adjust path as needed

# Ensure the config was loaded successfully
if not config:
    raise Exception("Failed to load configuration.")

# Load the dataset based on the path specified in the configuration
data_path = config['data_path']
diabetes_data = load_data(data_path)

# Ensure the data was loaded successfully
if diabetes_data is None:
    raise Exception("Failed to load the data.")

# Function to plot the distribution for each numerical feature
def plot_feature_distributions(df):
    """Plot histograms and box plots for each numerical feature in the dataframe."""
    for column in df.select_dtypes(include=['float64', 'int64']).columns:
        fig = px.histogram(df, x=column, marginal="box", title=f'Distribution of {column}')
        fig.show()

# Function to visualize the correlation matrix of features
def plot_correlation_matrix(df):
    """Generate a heatmap representing the correlation matrix of the dataframe's features."""
    corr_matrix = df.corr()
    fig = ff.create_annotated_heatmap(
        z=corr_matrix.to_numpy(),
        x=list(corr_matrix.columns),
        y=list(corr_matrix.index),
        annotation_text=corr_matrix.round(2).to_numpy(),
        colorscale='Viridis',
        showscale=True
        )
        fig.update_layout(title_text='Feature Correlation Matrix', title_x=0.5)
    fig.show()

# Function to compare the distribution of variables across different categories
def plot_variable_relationships(df, target):
    """Plot box plots for each numerical feature across different categories of the target variable."""
    features = df.select_dtypes(include=['float64', 'int64']).columns.drop(target)
    for feature in features:
        fig = px.box(df, x=target, y=feature, color=target, title=f'{feature} Distribution by {target}')
        fig.show()

# Function to analyze the distribution of the target variable
def plot_target_distribution(df, target):
    """Plot a histogram to show the distribution of the target variable."""
    fig = px.histogram(df, x=target, title=f'Distribution of {target}')
    fig.show()

# Conducting EDA
print("Conducting Exploratory Data Analysis...")
plot_feature_distributions(diabetes_data)
plot_correlation_matrix(diabetes_data)
plot_variable_relationships(diabetes_data, 'Outcome')
plot_target_distribution(diabetes_data, 'Outcome')


04_feature_engineering
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, PolynomialFeatures
from sklearn.impute import KNNImputer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, auc
import sys 
sys.path.append('../Helpers')
from data_helpers import load_config, load_data



# Data loading and preprocessing
def load_and_preprocess_data(config_path):
    # Load configuration settings from a JSON file
    config = load_config(config_path)

    if not config:
        raise Exception("Failed to load configuration.")

    # Load the dataset
    data_path = config['data_path']
    df = load_data(data_path)

    if df is None:
        raise Exception("Failed to load the data.")

    # Handling missing values
    for col in ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']:
        df[col].replace(0, np.nan, inplace=True)
        
    df['BMI_Age_Interaction'] = df['BMI'] * df['Age']
    
    return df

# Splitting dataset
def split_dataset(df):
    X = df.drop('Outcome', axis=1)
    y = df['Outcome']
    return train_test_split(X, y, test_size=0.2, random_state=42)

# Building the model pipeline
def build_model_pipeline():
    imputer = KNNImputer(n_neighbors=5)
    scaler = StandardScaler()
    poly = PolynomialFeatures(degree=2, include_bias=False)
    classifier = RandomForestClassifier(random_state=42)

    pipeline = Pipeline(steps=[('imputer', imputer),
                               ('scaler', scaler),
                               ('poly', poly),
                               ('classifier', classifier)])
    return pipeline

# Model training
def train_model(pipeline, X_train, y_train):
    pipeline.fit(X_train, y_train)

# Updated model evaluation with ROC Curve plotting
def evaluate_model(pipeline, X_test, y_test):
    predictions = pipeline.predict(X_test)
    probabilities = pipeline.predict_proba(X_test)[:, 1]  # For ROC AUC score

    print("Classification Report:\n", classification_report(y_test, predictions))
    plot_confusion_matrix(y_test, predictions)
    plot_roc_curve(y_test, probabilities)

# Helper function to format confusion matrix labels
def format_confusion_matrix_labels(cm):
    group_names = ['True Negative', 'False Positive', 'False Negative', 'True Positive']
    group_counts = ["{0:0.0f}".format(value) for value in cm.flatten()]
    group_percentages = ["{0:.2%}".format(value) for value in cm.flatten()/np.sum(cm)]
    labels = [f"{v1}\n{v2}\n{v3}" for v1, v2, v3 in zip(group_names, group_counts, group_percentages)]
    return np.asarray(labels).reshape(2,2)

# Plotting confusion matrix
def plot_confusion_matrix(y_test, predictions):
    cm = confusion_matrix(y_test, predictions)
    labels = format_confusion_matrix_labels(cm)
    
    # Making the figsize larger to fit the labels
    plt.figure(figsize=(7,7))
    sns.heatmap(cm, annot=labels, fmt='s', cmap='Blues', cbar=False)
    plt.title('Confusion Matrix with Labels')
    plt.ylabel('Actual label')
    plt.xlabel('Predicted label')
    plt.show()

    
# Function to plot the ROC curve
def plot_roc_curve(y_test, probabilities):
    fpr, tpr, thresholds = roc_curve(y_test, probabilities)
    roc_auc = auc(fpr, tpr)
    plt.figure()
    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc="lower right")
    plt.show()
    


if __name__ == "__main__":
    df = load_and_preprocess_data('../config/config.json')
    X_train, X_test, y_train, y_test = split_dataset(df)
    pipeline = build_model_pipeline()
    train_model(pipeline, X_train, y_train)
    evaluate_model(pipeline, X_test, y_test)


05.modeling
# Import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold
from sklearn.preprocessing import StandardScaler, PolynomialFeatures
from sklearn.impute import KNNImputer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, auc, precision_recall_curve, average_precision_score
from sklearn.utils.class_weight import compute_class_weight
import sys
sys.path.append('../Helpers')  # Ensure this path is correct for your project structure
from data_helpers import load_config, load_data


def load_feature_engineered_data(config_path):
    """
    Loads the feature-engineered dataset from the specified path in the config file.
    """
    try:
        config = load_config(config_path)
        processed_data_path = config['processed_data_path']
        df = pd.read_csv(processed_data_path)
        print("Feature-engineered dataset successfully loaded.")
        return df
    except Exception as e:
        print(f"Failed to load feature-engineered dataset: {e}")
        return None


    
def evaluate_model(model, X_test, y_test):
    """
    Evaluates the model's performance and plots evaluation metrics.
    """
    predictions = model.predict(X_test)
    probs = model.predict_proba(X_test)[:, 1]
    fpr, tpr, _ = roc_curve(y_test, probs)
    roc_auc = auc(fpr, tpr)

    print("\nClassification Report:")
    print(classification_report(y_test, predictions))
    print("\nConfusion Matrix:")
    sns.heatmap(confusion_matrix(y_test, predictions), annot=True, fmt='d', cmap='Blues')
    plt.title('Confusion Matrix')
    plt.ylabel('Actual label')
    plt.xlabel('Predicted label')
    plt.show()
    
    print("\nROC AUC Score:", roc_auc)
    plt.figure()
    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)
    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC)')
    plt.legend(loc="lower right")
    plt.show()

if __name__ == "__main__":
    config_path = '../config/config.json'  # Adjust as necessary
    df = load_feature_engineered_data(config_path)
    
    if df is not None:
        X = df.drop('Outcome', axis=1)
        y = df['Outcome']
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

        model = RandomForestClassifier(random_state=42)
        model.fit(X_train, y_train)
        
        evaluate_model(model, X_test, y_test)




evaluation_and_interpretation_06

from sklearn.metrics import precision_recall_curve, average_precision_score
import matplotlib.pyplot as plt

config = load_config('../config/config.json')  # Adjust as necessary
df = load_data(config['data_path'])


def plot_precision_recall_curve(y_test, probabilities):
    precision, recall, _ = precision_recall_curve(y_test, probabilities)
    average_precision = average_precision_score(y_test, probabilities)

    plt.figure()
    plt.step(recall, precision, color='b', alpha=0.2, where='post')
    plt.fill_between(recall, precision, step='post', alpha=0.2, color='b')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.ylim([0.0, 1.05])
    plt.xlim([0.0, 1.0])
    plt.title(f'Precision-Recall curve: AP={average_precision:0.2f}')
    plt.show()

# Assuming 'y_test' and 'probabilities' are defined (from your model predictions)
# plot_precision_recall_curve(y_test, probabilities)