{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f16afcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import sys \n",
    "sys.path.append('../Helpers')\n",
    "from data_helpers import load_config, load_data\n",
    "\n",
    "\n",
    "# Data loading and preprocessing\n",
    "def load_and_preprocess_data(config_path):\n",
    "    # Load configuration settings from a JSON file\n",
    "    config = load_config(config_path)\n",
    "\n",
    "    if not config:\n",
    "        raise Exception(\"Failed to load configuration.\")\n",
    "\n",
    "    # Load the dataset\n",
    "    data_path = config['data_path']\n",
    "    df = load_data(data_path)\n",
    "\n",
    "    if df is None:\n",
    "        raise Exception(\"Failed to load the data.\")\n",
    "\n",
    "    # Handling missing values\n",
    "    for col in ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']:\n",
    "        df[col].replace(0, np.nan, inplace=True)\n",
    "        \n",
    "    df['BMI_Age_Interaction'] = df['BMI'] * df['Age']\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Splitting dataset\n",
    "def split_dataset(df):\n",
    "    X = df.drop('Outcome', axis=1)\n",
    "    y = df['Outcome']\n",
    "    return train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Revised model pipeline construction with class weight handling\n",
    "def build_model_pipeline(class_weight):\n",
    "    imputer = KNNImputer(n_neighbors=5)\n",
    "    scaler = StandardScaler()\n",
    "    poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "    classifier = RandomForestClassifier(random_state=42, class_weight=class_weight)\n",
    "\n",
    "    pipeline = Pipeline(steps=[('imputer', imputer),\n",
    "                               ('scaler', scaler),\n",
    "                               ('poly', poly),\n",
    "                               ('classifier', classifier)])\n",
    "    return pipeline\n",
    "\n",
    "# Hyperparameter tuning using grid search\n",
    "def hyperparameter_tuning(X_train, y_train, class_weight):\n",
    "    pipeline = build_model_pipeline(class_weight)\n",
    "    parameter_grid = {\n",
    "        'classifier__n_estimators': [100, 200],\n",
    "        'classifier__max_depth': [None, 10, 20],\n",
    "        'classifier__min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "    cv = StratifiedKFold(n_splits=5)\n",
    "    grid_search = GridSearchCV(pipeline, parameter_grid, cv=cv, scoring='recall')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    return grid_search.best_estimator_\n",
    "\n",
    "\n",
    "\n",
    "# Function to find the optimal threshold for classification\n",
    "def find_optimal_threshold(precision, recall, thresholds):\n",
    "    # Convert to a f1 score and find the index of the highest score\n",
    "    f1_scores = 2 * recall * precision / (recall + precision)\n",
    "    optimal_idx = np.argmax(f1_scores)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    return optimal_threshold\n",
    "\n",
    "# Updated model evaluation with Precision-Recall curve and optimal threshold calculation\n",
    "def evaluate_model(pipeline, X_test, y_test):\n",
    "    # Predict probabilities and compute the probabilities for the positive class\n",
    "    probabilities = pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Compute ROC curve and ROC AUC score\n",
    "    fpr, tpr, roc_thresholds = roc_curve(y_test, probabilities)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plot_roc_curve(y_test, probabilities) \n",
    "\n",
    "    # Compute Precision-Recall curve and PR AUC score\n",
    "    precision, recall, pr_thresholds = precision_recall_curve(y_test, probabilities)\n",
    "    pr_auc = average_precision_score(y_test, probabilities)\n",
    "    plot_precision_recall_curve(recall, precision, pr_auc)\n",
    "\n",
    "    # Find the optimal threshold from the precision-recall curve\n",
    "    optimal_threshold = find_optimal_threshold(precision, recall, pr_thresholds)\n",
    "    \n",
    "    # Adjust predictions based on the optimal threshold\n",
    "    adjusted_predictions = [1 if prob > optimal_threshold else 0 for prob in probabilities]\n",
    "    \n",
    "    # Classification report using adjusted predictions\n",
    "    print(\"\\nAdjusted Classification Report:\")\n",
    "    print(classification_report(y_test, adjusted_predictions))\n",
    "\n",
    "    # Plot adjusted confusion matrix\n",
    "    adjusted_cm = confusion_matrix(y_test, adjusted_predictions)\n",
    "    plot_confusion_matrix(adjusted_cm)\n",
    "\n",
    "# Function to plot the Precision-Recall curve\n",
    "def plot_precision_recall_curve(y_test, probabilities):\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, probabilities)\n",
    "    pr_auc = average_precision_score(y_test, probabilities)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(recall, precision, color='blue', lw=2, label=f'PR curve (area = {pr_auc:.2f})')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve')\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.show()\n",
    "    \n",
    "# Function to plot the ROC curve\n",
    "def plot_roc_curve(y_test, probabilities):\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, probabilities)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm):\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    df = load_and_preprocess_data('../config/config.json')\n",
    "    X_train, X_test, y_train, y_test = split_dataset(df)\n",
    "    \n",
    "    # Compute class weights for imbalanced classes\n",
    "    class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "    class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "    # Perform hyperparameter tuning\n",
    "    best_pipeline = hyperparameter_tuning(X_train, y_train, class_weight_dict)\n",
    "    \n",
    "    # Evaluate the best model\n",
    "    evaluate_model(best_pipeline, X_test, y_test)\n",
    "\n",
    "    # Plot Precision-Recall curve\n",
    "    probabilities = best_pipeline.predict_proba(X_test)[:, 1]  # For PR AUC score\n",
    "    plot_precision_recall_curve(y_test, probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78347b26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfaf519",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50954ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
